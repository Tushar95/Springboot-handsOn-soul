# âš¡ Resilience4j Demo with Spring Boot

This project demonstrates **Resilience4j** fault-tolerance patterns in a real-world Spring Boot setup.  
It includes **Circuit Breaker, Retry, Rate Limiter, Time Limiter, Bulkhead, and Fallbacks** with hands-on examples. ğŸš€

---

## ğŸ”¥ Features Covered
âœ… CircuitBreaker â€“ stop calling unhealthy services  
âœ… Retry â€“ auto retry failed calls  
âœ… RateLimiter â€“ control request floods  
âœ… TimeLimiter â€“ timeout for slow services  
âœ… Bulkhead â€“ prevent resource exhaustion  
âœ… Fallback â€“ graceful degradation  

---

## ğŸ“‚ Project Structure
resilience4j-demo

ğŸ“Œ Description:
A Spring Boot project with two services:

Service A (client) â†’ Calls Service B.

Service B (server) â†’ Intentionally unstable (sometimes fails, delays, or throws errors).

You apply:

CircuitBreaker, Retry on Service A calling Service B

RateLimiter to protect Service B

TimeLimiter to cancel long requests

Fallbacks to provide default responses

â”£ ğŸ“¦ service-a (client, calls service-b with resilience4j)
â”£ ğŸ“¦ service-b (unstable service with random delays/failures)


## Resilience4j Components & How They Fit

Resilience4j provides different fault-tolerance patterns. Each one solves a specific issue in distributed, large-scale microservice architecture:

1. CircuitBreaker â†’ Prevents cascading failures by stopping calls to a failing service until it recovers.

2. Retry â†’ Automatically retries failed operations before giving up.

3. RateLimiter â†’ Limits number of calls in a time window (protects services from overload).

4. Bulkhead â†’ Restricts concurrent calls to isolate failures. (Thread-pool or semaphore isolation).

5. TimeLimiter â†’ Sets max time a request can run (cancels slow calls).

6. Cache â†’ Caches successful responses to reduce load on backend.

7. Fallback (with Spring Boot integration) â†’ Provides alternative response when primary fails.

---

## ğŸ”¹ 1. What `resilience4j-spring-boot3` actually is

* Think of `resilience4j-spring-boot3` as the **Spring Boot auto-configuration + annotation support layer**.
* It **does not include all the individual modules** (circuit breaker, retry, etc.) â€” it just wires them into Spring Boot if you add them.

ğŸ‘‰ In other words:

* `resilience4j-spring-boot3` = *â€œSpring Boot glue codeâ€*
* Actual resilience logic still comes from `resilience4j-circuitbreaker`, `resilience4j-retry`, `resilience4j-ratelimiter`, etc.

---

## ğŸ”¹ 2. Why add `circuitbreaker` and `retry` explicitly?

Because:

* `resilience4j-spring-boot3` alone doesnâ€™t contain the **implementation** of circuit breaker, retry, bulkhead, etc.
* If you donâ€™t add `resilience4j-circuitbreaker`, the annotation `@CircuitBreaker` wonâ€™t work (because the core logic is missing).
* Same with `@Retry`, `@RateLimiter`, `@Bulkhead`, etc.

So **you always need at least two parts**:

1. **The core module(s)** (like `resilience4j-circuitbreaker`)
2. **The Spring Boot integration layer** (`resilience4j-spring-boot3`)

---

## ğŸ”¹ 3. Whatâ€™s the "core" of Resilience4j?

At its heart, Resilience4j is just a **set of functional interfaces + decorators** that wrap calls with fault-tolerant behavior.

* `resilience4j-core` is the **foundation** module â€” all others depend on it.
* Example: a **circuit breaker** is basically a `Function<T,R>` wrapper that checks if calls should pass through or fail-fast.
* Retry, Bulkhead, TimeLimiter, etc. are separate implementations built on top of `core`.

---

## ğŸ”¹ 4. Practical dependency strategy

If you are using Spring Boot 3:

* âœ… Always include `resilience4j-spring-boot3`
* âœ… Add only the modules you really use (`circuitbreaker`, `retry`, etc.)
* âŒ Donâ€™t add everything blindly unless you really need them

Example minimal setup (CircuitBreaker + Retry only):

```kotlin
dependencies {
    implementation("io.github.resilience4j:resilience4j-spring-boot3:2.2.0")
    implementation("io.github.resilience4j:resilience4j-circuitbreaker:2.2.0")
    implementation("io.github.resilience4j:resilience4j-retry:2.2.0")
}
```

---

âœ… **In short**:

* `resilience4j-spring-boot3` = Spring Boot auto-configuration & annotations
* `resilience4j-circuitbreaker`, `resilience4j-retry`, etc. = actual resilience mechanisms
* You need both.

---

1. **Visibility into the CircuitBreaker state** (Closed â†’ Open â†’ Half-Open).
2. **Logs/metrics about retries and failures**.

Let me break this down step by step:

---

## ğŸ”¹ 1. Checking CircuitBreaker State

Resilience4j gives you the `CircuitBreakerRegistry` and `CircuitBreaker` instances directly:

```kotlin
import io.github.resilience4j.circuitbreaker.CircuitBreakerRegistry
import org.springframework.stereotype.Component

@Component
class CircuitBreakerInspector(val registry: CircuitBreakerRegistry) {

    fun checkState() {
        val cb = registry.circuitBreaker("myService")
        println("State: ${cb.state}")
    }
}
```

States you can see:

* `CLOSED` â†’ normal working
* `OPEN` â†’ all calls are blocked
* `HALF_OPEN` â†’ testing if the service has recovered

---

## ğŸ”¹ 2. Why the Circuit Breaker Opened (Failure Reasons)

Resilience4j counts:

* **Failed calls** (exceptions)
* **Slow calls** (if configured with a slow-call threshold)
* **Success calls**

You can get these details:

```kotlin
val cb = registry.circuitBreaker("myService")
val metrics = cb.metrics

println("Failure rate: ${metrics.failureRate}")
println("Number of failed calls: ${metrics.numberOfFailedCalls}")
println("Number of successful calls: ${metrics.numberOfSuccessfulCalls}")
println("Number of slow calls: ${metrics.numberOfSlowCalls}")
```

---

## ğŸ”¹ 3. How many retries happened?

Use `RetryRegistry`:

```kotlin
import io.github.resilience4j.retry.RetryRegistry

@Component
class RetryInspector(val registry: RetryRegistry) {

    fun checkRetries() {
        val retry = registry.retry("myService")
        val metrics = retry.metrics

        println("Number of successful calls without retry: ${metrics.numberOfSuccessfulCallsWithoutRetryAttempt}")
        println("Number of successful calls with retry: ${metrics.numberOfSuccessfulCallsWithRetryAttempt}")
        println("Number of failed calls with retry: ${metrics.numberOfFailedCallsWithRetryAttempt}")
    }
}
```

---

## ğŸ”¹ 4. Logging Events (Best Practice)

Instead of polling metrics, you can subscribe to **events**:

### Circuit Breaker Events

```kotlin
cb.eventPublisher
    .onStateTransition { e -> println("State transition: ${e.stateTransition}") }
    .onError { e -> println("Error recorded: ${e.throwable}") }
    .onSuccess { e -> println("Success: ${e.elapsedDuration}") }
```

### Retry Events

```kotlin
val retry = registry.retry("myService")

retry.eventPublisher
    .onRetry { e -> println("Retry attempt: ${e.numberOfRetryAttempts}, due to: ${e.lastThrowable?.message}") }
    .onSuccess { e -> println("Call succeeded after retry") }
```

---

## ğŸ”¹ 5. Observability via Actuator

If you add:

```kotlin
implementation("io.github.resilience4j:resilience4j-spring-boot3:2.2.0")
implementation("io.github.resilience4j:resilience4j-micrometer:2.2.0")
implementation("io.micrometer:micrometer-registry-prometheus")
```

â¡ You automatically get **Spring Boot Actuator endpoints**:

* `/actuator/metrics/resilience4j.circuitbreaker.calls`
* `/actuator/metrics/resilience4j.retry.calls`
* `/actuator/circuitbreakers` (shows all breakers + states)

This is the cleanest way in production.

---

## âœ… Summary

* **Check state** â†’ via `CircuitBreakerRegistry`
* **Reason for breaking** â†’ look at `metrics.failureRate`, failed/slow calls
* **Retries count** â†’ via `RetryRegistry.metrics`
* **Best logging** â†’ subscribe to event publishers (`onRetry`, `onStateTransition`, etc.)
* **Prod visibility** â†’ enable Resilience4j Actuator + Micrometer

---

# âš¡ Resilience4j Patterns â€” Best Practices

## 1. **CircuitBreaker (CB)**

* **Use for:** External dependencies that may fail repeatedly (APIs, DB, message broker).
* **Best practice:**

    * One CB per external dependency (e.g., `paymentService`, `shippingAPI`).
    * Configure in `application.yml`.
    * Always define a **fallback method**.

---

## 2. **Retry**

* **Use for:** Transient failures (e.g., network glitches, temporary 500s).
* **Best practice:**

    * Keep retry attempts low (2â€“3 max).
    * Combine with **CircuitBreaker** to avoid hammering a dead system.
    * Always have a **backoff policy** (like exponential delay).

Example config:

```yaml
resilience4j.retry:
  instances:
    paymentService:
      maxAttempts: 3
      waitDuration: 500ms
      enableExponentialBackoff: true
```

Usage:

```java
@Retry(name = "paymentService", fallbackMethod = "retryFallback")
public String callPayment() {
    return restTemplate.getForObject("https://api.example.com/pay", String.class);
}
```

---

## 3. **RateLimiter**

* **Use for:**

    * Protecting **your downstream service** from being overwhelmed.
    * Handling **third-party APIs with quotas** (e.g., 1000 req/min).
* **Best practice:**

    * Set `limitForPeriod` and `limitRefreshPeriod` according to API quota.
    * Apply **per-client or per-user** if you expose APIs.

Config:

```yaml
resilience4j.ratelimiter:
  instances:
    paymentService:
      limitForPeriod: 10
      limitRefreshPeriod: 1s
      timeoutDuration: 500ms
```

Usage:

```java
@RateLimiter(name = "paymentService", fallbackMethod = "rateLimitFallback")
public String callPayment() {
    return restTemplate.getForObject("https://api.example.com/pay", String.class);
}
```

---

## 4. **TimeLimiter**

* **Use for:** Ensuring you **donâ€™t wait too long** on a slow API.
* **Best practice:**

    * Wrap async calls (`CompletableFuture`, `Mono`, etc).
    * Always define a timeout smaller than your service SLA.
    * Combine with CB to avoid flooding a slow dependency.

Config:

```yaml
resilience4j.timelimiter:
  instances:
    paymentService:
      timeoutDuration: 2s
      cancelRunningFuture: true
```

Usage:

```java
@TimeLimiter(name = "paymentService")
public CompletableFuture<String> callPayment() {
    return CompletableFuture.supplyAsync(() ->
        restTemplate.getForObject("https://api.example.com/pay", String.class)
    );
}
```

---

# ğŸš€ Enterprise Best Practices (All Together)

âœ… **Layer patterns wisely**:

* `TimeLimiter` â†’ fail fast if itâ€™s too slow.
* `Retry` â†’ retry transient failures.
* `CircuitBreaker` â†’ trip if too many failures.
* `RateLimiter` â†’ ensure you donâ€™t overload yourself or hit quota.

âœ… **YAML-driven config**, not hardcoded. Keeps it flexible.

âœ… **Fallbacks for each pattern**:

* CB â†’ alternative response / cache.
* Retry â†’ final fallback if max attempts fail.
* RateLimiter â†’ â€œToo many requests, please retry later.â€
* TimeLimiter â†’ return cached/default response.

âœ… **One config per external system** (not per method).

âœ… **Metrics & Observability**:

* Expose via Actuator â†’ Prometheus â†’ Grafana.
* Monitor open CBs, retry counts, throttled requests.

---

### ğŸ”„ Example Composite Usage

```java
@CircuitBreaker(name = "paymentService", fallbackMethod = "cbFallback")
@Retry(name = "paymentService")
@RateLimiter(name = "paymentService")
@TimeLimiter(name = "paymentService")
public CompletableFuture<String> callPayment() {
    return CompletableFuture.supplyAsync(() ->
        restTemplate.getForObject("https://api.example.com/pay", String.class)
    );
}

public CompletableFuture<String> cbFallback(Throwable e) {
    return CompletableFuture.completedFuture("Payment fallback response");
}
```

